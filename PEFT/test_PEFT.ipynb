{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from peft import LoraConfig, get_peft_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:20:54.552543Z",
     "start_time": "2024-04-30T17:20:53.837228Z"
    }
   },
   "id": "670fb73ecd624ae8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:20:54.883632Z",
     "start_time": "2024-04-30T17:20:54.876062Z"
    }
   },
   "id": "feb87a784a781c93"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 25557032 || all params: 25557032 || trainable%: 100.00\n",
      "\n",
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer1.0\n",
      "layer1.0.conv1\n",
      "layer1.0.bn1\n",
      "layer1.0.conv2\n",
      "layer1.0.bn2\n",
      "layer1.0.conv3\n",
      "layer1.0.bn3\n",
      "layer1.0.relu\n",
      "layer1.0.downsample\n",
      "layer1.0.downsample.0\n",
      "layer1.0.downsample.1\n",
      "layer1.1\n",
      "layer1.1.conv1\n",
      "layer1.1.bn1\n",
      "layer1.1.conv2\n",
      "layer1.1.bn2\n",
      "layer1.1.conv3\n",
      "layer1.1.bn3\n",
      "layer1.1.relu\n",
      "layer1.2\n",
      "layer1.2.conv1\n",
      "layer1.2.bn1\n",
      "layer1.2.conv2\n",
      "layer1.2.bn2\n",
      "layer1.2.conv3\n",
      "layer1.2.bn3\n",
      "layer1.2.relu\n",
      "layer2\n",
      "layer2.0\n",
      "layer2.0.conv1\n",
      "layer2.0.bn1\n",
      "layer2.0.conv2\n",
      "layer2.0.bn2\n",
      "layer2.0.conv3\n",
      "layer2.0.bn3\n",
      "layer2.0.relu\n",
      "layer2.0.downsample\n",
      "layer2.0.downsample.0\n",
      "layer2.0.downsample.1\n",
      "layer2.1\n",
      "layer2.1.conv1\n",
      "layer2.1.bn1\n",
      "layer2.1.conv2\n",
      "layer2.1.bn2\n",
      "layer2.1.conv3\n",
      "layer2.1.bn3\n",
      "layer2.1.relu\n",
      "layer2.2\n",
      "layer2.2.conv1\n",
      "layer2.2.bn1\n",
      "layer2.2.conv2\n",
      "layer2.2.bn2\n",
      "layer2.2.conv3\n",
      "layer2.2.bn3\n",
      "layer2.2.relu\n",
      "layer2.3\n",
      "layer2.3.conv1\n",
      "layer2.3.bn1\n",
      "layer2.3.conv2\n",
      "layer2.3.bn2\n",
      "layer2.3.conv3\n",
      "layer2.3.bn3\n",
      "layer2.3.relu\n",
      "layer3\n",
      "layer3.0\n",
      "layer3.0.conv1\n",
      "layer3.0.bn1\n",
      "layer3.0.conv2\n",
      "layer3.0.bn2\n",
      "layer3.0.conv3\n",
      "layer3.0.bn3\n",
      "layer3.0.relu\n",
      "layer3.0.downsample\n",
      "layer3.0.downsample.0\n",
      "layer3.0.downsample.1\n",
      "layer3.1\n",
      "layer3.1.conv1\n",
      "layer3.1.bn1\n",
      "layer3.1.conv2\n",
      "layer3.1.bn2\n",
      "layer3.1.conv3\n",
      "layer3.1.bn3\n",
      "layer3.1.relu\n",
      "layer3.2\n",
      "layer3.2.conv1\n",
      "layer3.2.bn1\n",
      "layer3.2.conv2\n",
      "layer3.2.bn2\n",
      "layer3.2.conv3\n",
      "layer3.2.bn3\n",
      "layer3.2.relu\n",
      "layer3.3\n",
      "layer3.3.conv1\n",
      "layer3.3.bn1\n",
      "layer3.3.conv2\n",
      "layer3.3.bn2\n",
      "layer3.3.conv3\n",
      "layer3.3.bn3\n",
      "layer3.3.relu\n",
      "layer3.4\n",
      "layer3.4.conv1\n",
      "layer3.4.bn1\n",
      "layer3.4.conv2\n",
      "layer3.4.bn2\n",
      "layer3.4.conv3\n",
      "layer3.4.bn3\n",
      "layer3.4.relu\n",
      "layer3.5\n",
      "layer3.5.conv1\n",
      "layer3.5.bn1\n",
      "layer3.5.conv2\n",
      "layer3.5.bn2\n",
      "layer3.5.conv3\n",
      "layer3.5.bn3\n",
      "layer3.5.relu\n",
      "layer4\n",
      "layer4.0\n",
      "layer4.0.conv1\n",
      "layer4.0.bn1\n",
      "layer4.0.conv2\n",
      "layer4.0.bn2\n",
      "layer4.0.conv3\n",
      "layer4.0.bn3\n",
      "layer4.0.relu\n",
      "layer4.0.downsample\n",
      "layer4.0.downsample.0\n",
      "layer4.0.downsample.1\n",
      "layer4.1\n",
      "layer4.1.conv1\n",
      "layer4.1.bn1\n",
      "layer4.1.conv2\n",
      "layer4.1.bn2\n",
      "layer4.1.conv3\n",
      "layer4.1.bn3\n",
      "layer4.1.relu\n",
      "layer4.2\n",
      "layer4.2.conv1\n",
      "layer4.2.bn1\n",
      "layer4.2.conv2\n",
      "layer4.2.bn2\n",
      "layer4.2.conv3\n",
      "layer4.2.bn3\n",
      "layer4.2.relu\n",
      "avgpool\n",
      "fc\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# backbone: resnet\n",
    "from torchvision import models\n",
    "res_model = models.resnet50(pretrained=True)\n",
    "\n",
    "print_trainable_parameters(res_model)\n",
    "for name, module in res_model.named_modules():\n",
    "    print(name)\n",
    "print(res_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T00:57:08.554088Z",
     "start_time": "2024-04-27T00:57:07.879476Z"
    }
   },
   "id": "f2c45d439fc191ea"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2351080 || all params: 27908112 || trainable%: 8.42\n"
     ]
    }
   ],
   "source": [
    "# backbone: resnet + LoRA\n",
    "\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"conv3\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"],\n",
    ")\n",
    "lora_model = get_peft_model(res_model, config)\n",
    "print_trainable_parameters(lora_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T00:57:08.602258Z",
     "start_time": "2024-04-27T00:57:08.552679Z"
    }
   },
   "id": "9cbafabadb0204c6"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16130580 || all params: 39638612 || trainable%: 40.69\n",
      "\n",
      "backbone\n",
      "backbone.0\n",
      "backbone.1\n",
      "backbone.2\n",
      "backbone.3\n",
      "backbone.4\n",
      "backbone.4.0\n",
      "backbone.4.0.conv1\n",
      "backbone.4.0.bn1\n",
      "backbone.4.0.conv2\n",
      "backbone.4.0.bn2\n",
      "backbone.4.0.conv3\n",
      "backbone.4.0.bn3\n",
      "backbone.4.0.relu\n",
      "backbone.4.0.downsample\n",
      "backbone.4.0.downsample.0\n",
      "backbone.4.0.downsample.1\n",
      "backbone.4.1\n",
      "backbone.4.1.conv1\n",
      "backbone.4.1.bn1\n",
      "backbone.4.1.conv2\n",
      "backbone.4.1.bn2\n",
      "backbone.4.1.conv3\n",
      "backbone.4.1.bn3\n",
      "backbone.4.1.relu\n",
      "backbone.4.2\n",
      "backbone.4.2.conv1\n",
      "backbone.4.2.bn1\n",
      "backbone.4.2.conv2\n",
      "backbone.4.2.bn2\n",
      "backbone.4.2.conv3\n",
      "backbone.4.2.bn3\n",
      "backbone.4.2.relu\n",
      "backbone.5\n",
      "backbone.5.0\n",
      "backbone.5.0.conv1\n",
      "backbone.5.0.bn1\n",
      "backbone.5.0.conv2\n",
      "backbone.5.0.bn2\n",
      "backbone.5.0.conv3\n",
      "backbone.5.0.bn3\n",
      "backbone.5.0.relu\n",
      "backbone.5.0.downsample\n",
      "backbone.5.0.downsample.0\n",
      "backbone.5.0.downsample.1\n",
      "backbone.5.1\n",
      "backbone.5.1.conv1\n",
      "backbone.5.1.bn1\n",
      "backbone.5.1.conv2\n",
      "backbone.5.1.bn2\n",
      "backbone.5.1.conv3\n",
      "backbone.5.1.bn3\n",
      "backbone.5.1.relu\n",
      "backbone.5.2\n",
      "backbone.5.2.conv1\n",
      "backbone.5.2.bn1\n",
      "backbone.5.2.conv2\n",
      "backbone.5.2.bn2\n",
      "backbone.5.2.conv3\n",
      "backbone.5.2.bn3\n",
      "backbone.5.2.relu\n",
      "backbone.5.3\n",
      "backbone.5.3.conv1\n",
      "backbone.5.3.bn1\n",
      "backbone.5.3.conv2\n",
      "backbone.5.3.bn2\n",
      "backbone.5.3.conv3\n",
      "backbone.5.3.bn3\n",
      "backbone.5.3.relu\n",
      "backbone.6\n",
      "backbone.6.0\n",
      "backbone.6.0.conv1\n",
      "backbone.6.0.bn1\n",
      "backbone.6.0.conv2\n",
      "backbone.6.0.bn2\n",
      "backbone.6.0.conv3\n",
      "backbone.6.0.bn3\n",
      "backbone.6.0.relu\n",
      "backbone.6.0.downsample\n",
      "backbone.6.0.downsample.0\n",
      "backbone.6.0.downsample.1\n",
      "backbone.6.1\n",
      "backbone.6.1.conv1\n",
      "backbone.6.1.bn1\n",
      "backbone.6.1.conv2\n",
      "backbone.6.1.bn2\n",
      "backbone.6.1.conv3\n",
      "backbone.6.1.bn3\n",
      "backbone.6.1.relu\n",
      "backbone.6.2\n",
      "backbone.6.2.conv1\n",
      "backbone.6.2.bn1\n",
      "backbone.6.2.conv2\n",
      "backbone.6.2.bn2\n",
      "backbone.6.2.conv3\n",
      "backbone.6.2.bn3\n",
      "backbone.6.2.relu\n",
      "backbone.6.3\n",
      "backbone.6.3.conv1\n",
      "backbone.6.3.bn1\n",
      "backbone.6.3.conv2\n",
      "backbone.6.3.bn2\n",
      "backbone.6.3.conv3\n",
      "backbone.6.3.bn3\n",
      "backbone.6.3.relu\n",
      "backbone.6.4\n",
      "backbone.6.4.conv1\n",
      "backbone.6.4.bn1\n",
      "backbone.6.4.conv2\n",
      "backbone.6.4.bn2\n",
      "backbone.6.4.conv3\n",
      "backbone.6.4.bn3\n",
      "backbone.6.4.relu\n",
      "backbone.6.5\n",
      "backbone.6.5.conv1\n",
      "backbone.6.5.bn1\n",
      "backbone.6.5.conv2\n",
      "backbone.6.5.bn2\n",
      "backbone.6.5.conv3\n",
      "backbone.6.5.bn3\n",
      "backbone.6.5.relu\n",
      "backbone.7\n",
      "backbone.7.0\n",
      "backbone.7.0.conv1\n",
      "backbone.7.0.bn1\n",
      "backbone.7.0.conv2\n",
      "backbone.7.0.bn2\n",
      "backbone.7.0.conv3\n",
      "backbone.7.0.bn3\n",
      "backbone.7.0.relu\n",
      "backbone.7.0.downsample\n",
      "backbone.7.0.downsample.0\n",
      "backbone.7.0.downsample.1\n",
      "backbone.7.1\n",
      "backbone.7.1.conv1\n",
      "backbone.7.1.bn1\n",
      "backbone.7.1.conv2\n",
      "backbone.7.1.bn2\n",
      "backbone.7.1.conv3\n",
      "backbone.7.1.bn3\n",
      "backbone.7.1.relu\n",
      "backbone.7.2\n",
      "backbone.7.2.conv1\n",
      "backbone.7.2.bn1\n",
      "backbone.7.2.conv2\n",
      "backbone.7.2.bn2\n",
      "backbone.7.2.conv3\n",
      "backbone.7.2.bn3\n",
      "backbone.7.2.relu\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.0.convs\n",
      "classifier.0.convs.0\n",
      "classifier.0.convs.0.0\n",
      "classifier.0.convs.0.1\n",
      "classifier.0.convs.0.2\n",
      "classifier.0.convs.1\n",
      "classifier.0.convs.1.0\n",
      "classifier.0.convs.1.1\n",
      "classifier.0.convs.1.2\n",
      "classifier.0.convs.2\n",
      "classifier.0.convs.2.0\n",
      "classifier.0.convs.2.1\n",
      "classifier.0.convs.2.2\n",
      "classifier.0.convs.3\n",
      "classifier.0.convs.3.0\n",
      "classifier.0.convs.3.1\n",
      "classifier.0.convs.3.2\n",
      "classifier.0.convs.4\n",
      "classifier.0.convs.4.0\n",
      "classifier.0.convs.4.1\n",
      "classifier.0.convs.4.2\n",
      "classifier.0.convs.4.3\n",
      "classifier.0.project\n",
      "classifier.0.project.0\n",
      "classifier.0.project.1\n",
      "classifier.0.project.2\n",
      "classifier.0.project.3\n",
      "classifier.1\n",
      "classifier.2\n",
      "classifier.3\n",
      "classifier.4\n",
      "CustomDeepLabV3(\n",
      "  (backbone): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# segmentation_model 1.0: res50 + DeepLabV3\n",
    "class CustomDeepLabV3(torch.nn.Module):\n",
    "    def __init__(self, backbone, classifier):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        #print(\"size after downsampling\", features.shape)\n",
    "        x = self.classifier(features)\n",
    "        #print(\"size after segmentation head\", x.shape)\n",
    "        # spatial dimensions of this map are smaller than the original input image due to the downsampling operations in the backbone.\n",
    "        # We can upsample the output to the size of the input image using interpolation\n",
    "        x = torch.nn.functional.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        #print(\"size after upsampling\", x.shape)\n",
    "        return {'out': x}\n",
    "\n",
    "backbone = models.resnet50(pretrained=True)\n",
    "backbone = torch.nn.Sequential(*(list(backbone.children())[:-2])) # remove the last two layers\n",
    "# backbone.add_module('avgpool', torch.nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "\n",
    "num_classes = 20\n",
    "# the segmentation head is responsible for making the final pixel-wise predictions\n",
    "segmentation_head = DeepLabHead(2048, num_classes)\n",
    "# 2048 is the number of output channels in the resnet50 backbone\n",
    "for param in backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Then use your custom model instead of the original one\n",
    "model = CustomDeepLabV3(backbone, segmentation_head)\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T01:32:27.471478Z",
     "start_time": "2024-04-27T01:32:26.387888Z"
    }
   },
   "id": "1cba3515939924a6"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16734740 || all params: 40242772 || trainable%: 41.58\n",
      "\n",
      "backbone\n",
      "backbone.base_model\n",
      "backbone.base_model.model\n",
      "backbone.base_model.model.0\n",
      "backbone.base_model.model.1\n",
      "backbone.base_model.model.2\n",
      "backbone.base_model.model.3\n",
      "backbone.base_model.model.4\n",
      "backbone.base_model.model.4.0\n",
      "backbone.base_model.model.4.0.conv1\n",
      "backbone.base_model.model.4.0.bn1\n",
      "backbone.base_model.model.4.0.conv2\n",
      "backbone.base_model.model.4.0.conv2.base_layer\n",
      "backbone.base_model.model.4.0.conv2.lora_dropout\n",
      "backbone.base_model.model.4.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.4.0.conv2.lora_A\n",
      "backbone.base_model.model.4.0.conv2.lora_A.default\n",
      "backbone.base_model.model.4.0.conv2.lora_B\n",
      "backbone.base_model.model.4.0.conv2.lora_B.default\n",
      "backbone.base_model.model.4.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.4.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.4.0.bn2\n",
      "backbone.base_model.model.4.0.conv3\n",
      "backbone.base_model.model.4.0.bn3\n",
      "backbone.base_model.model.4.0.relu\n",
      "backbone.base_model.model.4.0.downsample\n",
      "backbone.base_model.model.4.0.downsample.0\n",
      "backbone.base_model.model.4.0.downsample.1\n",
      "backbone.base_model.model.4.1\n",
      "backbone.base_model.model.4.1.conv1\n",
      "backbone.base_model.model.4.1.bn1\n",
      "backbone.base_model.model.4.1.conv2\n",
      "backbone.base_model.model.4.1.conv2.base_layer\n",
      "backbone.base_model.model.4.1.conv2.lora_dropout\n",
      "backbone.base_model.model.4.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.4.1.conv2.lora_A\n",
      "backbone.base_model.model.4.1.conv2.lora_A.default\n",
      "backbone.base_model.model.4.1.conv2.lora_B\n",
      "backbone.base_model.model.4.1.conv2.lora_B.default\n",
      "backbone.base_model.model.4.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.4.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.4.1.bn2\n",
      "backbone.base_model.model.4.1.conv3\n",
      "backbone.base_model.model.4.1.bn3\n",
      "backbone.base_model.model.4.1.relu\n",
      "backbone.base_model.model.4.2\n",
      "backbone.base_model.model.4.2.conv1\n",
      "backbone.base_model.model.4.2.bn1\n",
      "backbone.base_model.model.4.2.conv2\n",
      "backbone.base_model.model.4.2.conv2.base_layer\n",
      "backbone.base_model.model.4.2.conv2.lora_dropout\n",
      "backbone.base_model.model.4.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.4.2.conv2.lora_A\n",
      "backbone.base_model.model.4.2.conv2.lora_A.default\n",
      "backbone.base_model.model.4.2.conv2.lora_B\n",
      "backbone.base_model.model.4.2.conv2.lora_B.default\n",
      "backbone.base_model.model.4.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.4.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.4.2.bn2\n",
      "backbone.base_model.model.4.2.conv3\n",
      "backbone.base_model.model.4.2.bn3\n",
      "backbone.base_model.model.4.2.relu\n",
      "backbone.base_model.model.5\n",
      "backbone.base_model.model.5.0\n",
      "backbone.base_model.model.5.0.conv1\n",
      "backbone.base_model.model.5.0.bn1\n",
      "backbone.base_model.model.5.0.conv2\n",
      "backbone.base_model.model.5.0.conv2.base_layer\n",
      "backbone.base_model.model.5.0.conv2.lora_dropout\n",
      "backbone.base_model.model.5.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.0.conv2.lora_A\n",
      "backbone.base_model.model.5.0.conv2.lora_A.default\n",
      "backbone.base_model.model.5.0.conv2.lora_B\n",
      "backbone.base_model.model.5.0.conv2.lora_B.default\n",
      "backbone.base_model.model.5.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.0.bn2\n",
      "backbone.base_model.model.5.0.conv3\n",
      "backbone.base_model.model.5.0.bn3\n",
      "backbone.base_model.model.5.0.relu\n",
      "backbone.base_model.model.5.0.downsample\n",
      "backbone.base_model.model.5.0.downsample.0\n",
      "backbone.base_model.model.5.0.downsample.1\n",
      "backbone.base_model.model.5.1\n",
      "backbone.base_model.model.5.1.conv1\n",
      "backbone.base_model.model.5.1.bn1\n",
      "backbone.base_model.model.5.1.conv2\n",
      "backbone.base_model.model.5.1.conv2.base_layer\n",
      "backbone.base_model.model.5.1.conv2.lora_dropout\n",
      "backbone.base_model.model.5.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.1.conv2.lora_A\n",
      "backbone.base_model.model.5.1.conv2.lora_A.default\n",
      "backbone.base_model.model.5.1.conv2.lora_B\n",
      "backbone.base_model.model.5.1.conv2.lora_B.default\n",
      "backbone.base_model.model.5.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.1.bn2\n",
      "backbone.base_model.model.5.1.conv3\n",
      "backbone.base_model.model.5.1.bn3\n",
      "backbone.base_model.model.5.1.relu\n",
      "backbone.base_model.model.5.2\n",
      "backbone.base_model.model.5.2.conv1\n",
      "backbone.base_model.model.5.2.bn1\n",
      "backbone.base_model.model.5.2.conv2\n",
      "backbone.base_model.model.5.2.conv2.base_layer\n",
      "backbone.base_model.model.5.2.conv2.lora_dropout\n",
      "backbone.base_model.model.5.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.2.conv2.lora_A\n",
      "backbone.base_model.model.5.2.conv2.lora_A.default\n",
      "backbone.base_model.model.5.2.conv2.lora_B\n",
      "backbone.base_model.model.5.2.conv2.lora_B.default\n",
      "backbone.base_model.model.5.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.2.bn2\n",
      "backbone.base_model.model.5.2.conv3\n",
      "backbone.base_model.model.5.2.bn3\n",
      "backbone.base_model.model.5.2.relu\n",
      "backbone.base_model.model.5.3\n",
      "backbone.base_model.model.5.3.conv1\n",
      "backbone.base_model.model.5.3.bn1\n",
      "backbone.base_model.model.5.3.conv2\n",
      "backbone.base_model.model.5.3.conv2.base_layer\n",
      "backbone.base_model.model.5.3.conv2.lora_dropout\n",
      "backbone.base_model.model.5.3.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.3.conv2.lora_A\n",
      "backbone.base_model.model.5.3.conv2.lora_A.default\n",
      "backbone.base_model.model.5.3.conv2.lora_B\n",
      "backbone.base_model.model.5.3.conv2.lora_B.default\n",
      "backbone.base_model.model.5.3.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.3.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.3.bn2\n",
      "backbone.base_model.model.5.3.conv3\n",
      "backbone.base_model.model.5.3.bn3\n",
      "backbone.base_model.model.5.3.relu\n",
      "backbone.base_model.model.6\n",
      "backbone.base_model.model.6.0\n",
      "backbone.base_model.model.6.0.conv1\n",
      "backbone.base_model.model.6.0.bn1\n",
      "backbone.base_model.model.6.0.conv2\n",
      "backbone.base_model.model.6.0.conv2.base_layer\n",
      "backbone.base_model.model.6.0.conv2.lora_dropout\n",
      "backbone.base_model.model.6.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.0.conv2.lora_A\n",
      "backbone.base_model.model.6.0.conv2.lora_A.default\n",
      "backbone.base_model.model.6.0.conv2.lora_B\n",
      "backbone.base_model.model.6.0.conv2.lora_B.default\n",
      "backbone.base_model.model.6.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.0.bn2\n",
      "backbone.base_model.model.6.0.conv3\n",
      "backbone.base_model.model.6.0.bn3\n",
      "backbone.base_model.model.6.0.relu\n",
      "backbone.base_model.model.6.0.downsample\n",
      "backbone.base_model.model.6.0.downsample.0\n",
      "backbone.base_model.model.6.0.downsample.1\n",
      "backbone.base_model.model.6.1\n",
      "backbone.base_model.model.6.1.conv1\n",
      "backbone.base_model.model.6.1.bn1\n",
      "backbone.base_model.model.6.1.conv2\n",
      "backbone.base_model.model.6.1.conv2.base_layer\n",
      "backbone.base_model.model.6.1.conv2.lora_dropout\n",
      "backbone.base_model.model.6.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.1.conv2.lora_A\n",
      "backbone.base_model.model.6.1.conv2.lora_A.default\n",
      "backbone.base_model.model.6.1.conv2.lora_B\n",
      "backbone.base_model.model.6.1.conv2.lora_B.default\n",
      "backbone.base_model.model.6.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.1.bn2\n",
      "backbone.base_model.model.6.1.conv3\n",
      "backbone.base_model.model.6.1.bn3\n",
      "backbone.base_model.model.6.1.relu\n",
      "backbone.base_model.model.6.2\n",
      "backbone.base_model.model.6.2.conv1\n",
      "backbone.base_model.model.6.2.bn1\n",
      "backbone.base_model.model.6.2.conv2\n",
      "backbone.base_model.model.6.2.conv2.base_layer\n",
      "backbone.base_model.model.6.2.conv2.lora_dropout\n",
      "backbone.base_model.model.6.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.2.conv2.lora_A\n",
      "backbone.base_model.model.6.2.conv2.lora_A.default\n",
      "backbone.base_model.model.6.2.conv2.lora_B\n",
      "backbone.base_model.model.6.2.conv2.lora_B.default\n",
      "backbone.base_model.model.6.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.2.bn2\n",
      "backbone.base_model.model.6.2.conv3\n",
      "backbone.base_model.model.6.2.bn3\n",
      "backbone.base_model.model.6.2.relu\n",
      "backbone.base_model.model.6.3\n",
      "backbone.base_model.model.6.3.conv1\n",
      "backbone.base_model.model.6.3.bn1\n",
      "backbone.base_model.model.6.3.conv2\n",
      "backbone.base_model.model.6.3.conv2.base_layer\n",
      "backbone.base_model.model.6.3.conv2.lora_dropout\n",
      "backbone.base_model.model.6.3.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.3.conv2.lora_A\n",
      "backbone.base_model.model.6.3.conv2.lora_A.default\n",
      "backbone.base_model.model.6.3.conv2.lora_B\n",
      "backbone.base_model.model.6.3.conv2.lora_B.default\n",
      "backbone.base_model.model.6.3.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.3.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.3.bn2\n",
      "backbone.base_model.model.6.3.conv3\n",
      "backbone.base_model.model.6.3.bn3\n",
      "backbone.base_model.model.6.3.relu\n",
      "backbone.base_model.model.6.4\n",
      "backbone.base_model.model.6.4.conv1\n",
      "backbone.base_model.model.6.4.bn1\n",
      "backbone.base_model.model.6.4.conv2\n",
      "backbone.base_model.model.6.4.conv2.base_layer\n",
      "backbone.base_model.model.6.4.conv2.lora_dropout\n",
      "backbone.base_model.model.6.4.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.4.conv2.lora_A\n",
      "backbone.base_model.model.6.4.conv2.lora_A.default\n",
      "backbone.base_model.model.6.4.conv2.lora_B\n",
      "backbone.base_model.model.6.4.conv2.lora_B.default\n",
      "backbone.base_model.model.6.4.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.4.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.4.bn2\n",
      "backbone.base_model.model.6.4.conv3\n",
      "backbone.base_model.model.6.4.bn3\n",
      "backbone.base_model.model.6.4.relu\n",
      "backbone.base_model.model.6.5\n",
      "backbone.base_model.model.6.5.conv1\n",
      "backbone.base_model.model.6.5.bn1\n",
      "backbone.base_model.model.6.5.conv2\n",
      "backbone.base_model.model.6.5.conv2.base_layer\n",
      "backbone.base_model.model.6.5.conv2.lora_dropout\n",
      "backbone.base_model.model.6.5.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.5.conv2.lora_A\n",
      "backbone.base_model.model.6.5.conv2.lora_A.default\n",
      "backbone.base_model.model.6.5.conv2.lora_B\n",
      "backbone.base_model.model.6.5.conv2.lora_B.default\n",
      "backbone.base_model.model.6.5.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.5.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.5.bn2\n",
      "backbone.base_model.model.6.5.conv3\n",
      "backbone.base_model.model.6.5.bn3\n",
      "backbone.base_model.model.6.5.relu\n",
      "backbone.base_model.model.7\n",
      "backbone.base_model.model.7.0\n",
      "backbone.base_model.model.7.0.conv1\n",
      "backbone.base_model.model.7.0.bn1\n",
      "backbone.base_model.model.7.0.conv2\n",
      "backbone.base_model.model.7.0.conv2.base_layer\n",
      "backbone.base_model.model.7.0.conv2.lora_dropout\n",
      "backbone.base_model.model.7.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.7.0.conv2.lora_A\n",
      "backbone.base_model.model.7.0.conv2.lora_A.default\n",
      "backbone.base_model.model.7.0.conv2.lora_B\n",
      "backbone.base_model.model.7.0.conv2.lora_B.default\n",
      "backbone.base_model.model.7.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.7.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.7.0.bn2\n",
      "backbone.base_model.model.7.0.conv3\n",
      "backbone.base_model.model.7.0.bn3\n",
      "backbone.base_model.model.7.0.relu\n",
      "backbone.base_model.model.7.0.downsample\n",
      "backbone.base_model.model.7.0.downsample.0\n",
      "backbone.base_model.model.7.0.downsample.1\n",
      "backbone.base_model.model.7.1\n",
      "backbone.base_model.model.7.1.conv1\n",
      "backbone.base_model.model.7.1.bn1\n",
      "backbone.base_model.model.7.1.conv2\n",
      "backbone.base_model.model.7.1.conv2.base_layer\n",
      "backbone.base_model.model.7.1.conv2.lora_dropout\n",
      "backbone.base_model.model.7.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.7.1.conv2.lora_A\n",
      "backbone.base_model.model.7.1.conv2.lora_A.default\n",
      "backbone.base_model.model.7.1.conv2.lora_B\n",
      "backbone.base_model.model.7.1.conv2.lora_B.default\n",
      "backbone.base_model.model.7.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.7.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.7.1.bn2\n",
      "backbone.base_model.model.7.1.conv3\n",
      "backbone.base_model.model.7.1.bn3\n",
      "backbone.base_model.model.7.1.relu\n",
      "backbone.base_model.model.7.2\n",
      "backbone.base_model.model.7.2.conv1\n",
      "backbone.base_model.model.7.2.bn1\n",
      "backbone.base_model.model.7.2.conv2\n",
      "backbone.base_model.model.7.2.conv2.base_layer\n",
      "backbone.base_model.model.7.2.conv2.lora_dropout\n",
      "backbone.base_model.model.7.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.7.2.conv2.lora_A\n",
      "backbone.base_model.model.7.2.conv2.lora_A.default\n",
      "backbone.base_model.model.7.2.conv2.lora_B\n",
      "backbone.base_model.model.7.2.conv2.lora_B.default\n",
      "backbone.base_model.model.7.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.7.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.7.2.bn2\n",
      "backbone.base_model.model.7.2.conv3\n",
      "backbone.base_model.model.7.2.bn3\n",
      "backbone.base_model.model.7.2.relu\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.0.convs\n",
      "classifier.0.convs.0\n",
      "classifier.0.convs.0.0\n",
      "classifier.0.convs.0.1\n",
      "classifier.0.convs.0.2\n",
      "classifier.0.convs.1\n",
      "classifier.0.convs.1.0\n",
      "classifier.0.convs.1.1\n",
      "classifier.0.convs.1.2\n",
      "classifier.0.convs.2\n",
      "classifier.0.convs.2.0\n",
      "classifier.0.convs.2.1\n",
      "classifier.0.convs.2.2\n",
      "classifier.0.convs.3\n",
      "classifier.0.convs.3.0\n",
      "classifier.0.convs.3.1\n",
      "classifier.0.convs.3.2\n",
      "classifier.0.convs.4\n",
      "classifier.0.convs.4.0\n",
      "classifier.0.convs.4.1\n",
      "classifier.0.convs.4.2\n",
      "classifier.0.convs.4.3\n",
      "classifier.0.project\n",
      "classifier.0.project.0\n",
      "classifier.0.project.1\n",
      "classifier.0.project.2\n",
      "classifier.0.project.3\n",
      "classifier.1\n",
      "classifier.2\n",
      "classifier.3\n",
      "classifier.4\n",
      "CustomDeepLabV3(\n",
      "  (backbone): PeftModel(\n",
      "    (base_model): LoraModel(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# segmentation_model 1.1: res50 + LoRA(conv2) + DeepLabV3\n",
    "class CustomDeepLabV3(torch.nn.Module):\n",
    "    def __init__(self, backbone, classifier):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        #print(\"size after downsampling\", features.shape)\n",
    "        x = self.classifier(features)\n",
    "        #print(\"size after segmentation head\", x.shape)\n",
    "        # spatial dimensions of this map are smaller than the original input image due to the downsampling operations in the backbone.\n",
    "        # We can upsample the output to the size of the input image using interpolation\n",
    "        x = torch.nn.functional.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        #print(\"size after upsampling\", x.shape)\n",
    "        return {'out': x}\n",
    "\n",
    "backbone = models.resnet50(pretrained=True)\n",
    "backbone = torch.nn.Sequential(*(list(backbone.children())[:-2])) # remove the last two layers\n",
    "# backbone.add_module('avgpool', torch.nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "\n",
    "num_classes = 20\n",
    "# the segmentation head is responsible for making the final pixel-wise predictions\n",
    "segmentation_head = DeepLabHead(2048, num_classes)\n",
    "# 2048 is the number of output channels in the resnet50 backbone\n",
    "\n",
    "# Then use your custom model instead of the original one\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"conv2\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"],\n",
    ")\n",
    "backbone = get_peft_model(backbone, config)\n",
    "\n",
    "model = CustomDeepLabV3(backbone, segmentation_head)\n",
    "    \n",
    "print_trainable_parameters(model)\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T02:14:29.931315Z",
     "start_time": "2024-04-27T02:14:29.316969Z"
    }
   },
   "id": "f9c84547efdcc89f"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16432660 || all params: 39940692 || trainable%: 41.14\n",
      "\n",
      "backbone\n",
      "backbone.base_model\n",
      "backbone.base_model.model\n",
      "backbone.base_model.model.0\n",
      "backbone.base_model.model.1\n",
      "backbone.base_model.model.2\n",
      "backbone.base_model.model.3\n",
      "backbone.base_model.model.4\n",
      "backbone.base_model.model.4.0\n",
      "backbone.base_model.model.4.0.conv1\n",
      "backbone.base_model.model.4.0.bn1\n",
      "backbone.base_model.model.4.0.conv2\n",
      "backbone.base_model.model.4.0.bn2\n",
      "backbone.base_model.model.4.0.conv3\n",
      "backbone.base_model.model.4.0.conv3.base_layer\n",
      "backbone.base_model.model.4.0.conv3.lora_dropout\n",
      "backbone.base_model.model.4.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.4.0.conv3.lora_A\n",
      "backbone.base_model.model.4.0.conv3.lora_A.default\n",
      "backbone.base_model.model.4.0.conv3.lora_B\n",
      "backbone.base_model.model.4.0.conv3.lora_B.default\n",
      "backbone.base_model.model.4.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.4.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.4.0.bn3\n",
      "backbone.base_model.model.4.0.relu\n",
      "backbone.base_model.model.4.0.downsample\n",
      "backbone.base_model.model.4.0.downsample.0\n",
      "backbone.base_model.model.4.0.downsample.1\n",
      "backbone.base_model.model.4.1\n",
      "backbone.base_model.model.4.1.conv1\n",
      "backbone.base_model.model.4.1.bn1\n",
      "backbone.base_model.model.4.1.conv2\n",
      "backbone.base_model.model.4.1.bn2\n",
      "backbone.base_model.model.4.1.conv3\n",
      "backbone.base_model.model.4.1.conv3.base_layer\n",
      "backbone.base_model.model.4.1.conv3.lora_dropout\n",
      "backbone.base_model.model.4.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.4.1.conv3.lora_A\n",
      "backbone.base_model.model.4.1.conv3.lora_A.default\n",
      "backbone.base_model.model.4.1.conv3.lora_B\n",
      "backbone.base_model.model.4.1.conv3.lora_B.default\n",
      "backbone.base_model.model.4.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.4.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.4.1.bn3\n",
      "backbone.base_model.model.4.1.relu\n",
      "backbone.base_model.model.4.2\n",
      "backbone.base_model.model.4.2.conv1\n",
      "backbone.base_model.model.4.2.bn1\n",
      "backbone.base_model.model.4.2.conv2\n",
      "backbone.base_model.model.4.2.bn2\n",
      "backbone.base_model.model.4.2.conv3\n",
      "backbone.base_model.model.4.2.conv3.base_layer\n",
      "backbone.base_model.model.4.2.conv3.lora_dropout\n",
      "backbone.base_model.model.4.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.4.2.conv3.lora_A\n",
      "backbone.base_model.model.4.2.conv3.lora_A.default\n",
      "backbone.base_model.model.4.2.conv3.lora_B\n",
      "backbone.base_model.model.4.2.conv3.lora_B.default\n",
      "backbone.base_model.model.4.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.4.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.4.2.bn3\n",
      "backbone.base_model.model.4.2.relu\n",
      "backbone.base_model.model.5\n",
      "backbone.base_model.model.5.0\n",
      "backbone.base_model.model.5.0.conv1\n",
      "backbone.base_model.model.5.0.bn1\n",
      "backbone.base_model.model.5.0.conv2\n",
      "backbone.base_model.model.5.0.bn2\n",
      "backbone.base_model.model.5.0.conv3\n",
      "backbone.base_model.model.5.0.conv3.base_layer\n",
      "backbone.base_model.model.5.0.conv3.lora_dropout\n",
      "backbone.base_model.model.5.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.0.conv3.lora_A\n",
      "backbone.base_model.model.5.0.conv3.lora_A.default\n",
      "backbone.base_model.model.5.0.conv3.lora_B\n",
      "backbone.base_model.model.5.0.conv3.lora_B.default\n",
      "backbone.base_model.model.5.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.0.bn3\n",
      "backbone.base_model.model.5.0.relu\n",
      "backbone.base_model.model.5.0.downsample\n",
      "backbone.base_model.model.5.0.downsample.0\n",
      "backbone.base_model.model.5.0.downsample.1\n",
      "backbone.base_model.model.5.1\n",
      "backbone.base_model.model.5.1.conv1\n",
      "backbone.base_model.model.5.1.bn1\n",
      "backbone.base_model.model.5.1.conv2\n",
      "backbone.base_model.model.5.1.bn2\n",
      "backbone.base_model.model.5.1.conv3\n",
      "backbone.base_model.model.5.1.conv3.base_layer\n",
      "backbone.base_model.model.5.1.conv3.lora_dropout\n",
      "backbone.base_model.model.5.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.1.conv3.lora_A\n",
      "backbone.base_model.model.5.1.conv3.lora_A.default\n",
      "backbone.base_model.model.5.1.conv3.lora_B\n",
      "backbone.base_model.model.5.1.conv3.lora_B.default\n",
      "backbone.base_model.model.5.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.1.bn3\n",
      "backbone.base_model.model.5.1.relu\n",
      "backbone.base_model.model.5.2\n",
      "backbone.base_model.model.5.2.conv1\n",
      "backbone.base_model.model.5.2.bn1\n",
      "backbone.base_model.model.5.2.conv2\n",
      "backbone.base_model.model.5.2.bn2\n",
      "backbone.base_model.model.5.2.conv3\n",
      "backbone.base_model.model.5.2.conv3.base_layer\n",
      "backbone.base_model.model.5.2.conv3.lora_dropout\n",
      "backbone.base_model.model.5.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.2.conv3.lora_A\n",
      "backbone.base_model.model.5.2.conv3.lora_A.default\n",
      "backbone.base_model.model.5.2.conv3.lora_B\n",
      "backbone.base_model.model.5.2.conv3.lora_B.default\n",
      "backbone.base_model.model.5.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.2.bn3\n",
      "backbone.base_model.model.5.2.relu\n",
      "backbone.base_model.model.5.3\n",
      "backbone.base_model.model.5.3.conv1\n",
      "backbone.base_model.model.5.3.bn1\n",
      "backbone.base_model.model.5.3.conv2\n",
      "backbone.base_model.model.5.3.bn2\n",
      "backbone.base_model.model.5.3.conv3\n",
      "backbone.base_model.model.5.3.conv3.base_layer\n",
      "backbone.base_model.model.5.3.conv3.lora_dropout\n",
      "backbone.base_model.model.5.3.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.3.conv3.lora_A\n",
      "backbone.base_model.model.5.3.conv3.lora_A.default\n",
      "backbone.base_model.model.5.3.conv3.lora_B\n",
      "backbone.base_model.model.5.3.conv3.lora_B.default\n",
      "backbone.base_model.model.5.3.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.3.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.3.bn3\n",
      "backbone.base_model.model.5.3.relu\n",
      "backbone.base_model.model.6\n",
      "backbone.base_model.model.6.0\n",
      "backbone.base_model.model.6.0.conv1\n",
      "backbone.base_model.model.6.0.bn1\n",
      "backbone.base_model.model.6.0.conv2\n",
      "backbone.base_model.model.6.0.bn2\n",
      "backbone.base_model.model.6.0.conv3\n",
      "backbone.base_model.model.6.0.conv3.base_layer\n",
      "backbone.base_model.model.6.0.conv3.lora_dropout\n",
      "backbone.base_model.model.6.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.0.conv3.lora_A\n",
      "backbone.base_model.model.6.0.conv3.lora_A.default\n",
      "backbone.base_model.model.6.0.conv3.lora_B\n",
      "backbone.base_model.model.6.0.conv3.lora_B.default\n",
      "backbone.base_model.model.6.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.0.bn3\n",
      "backbone.base_model.model.6.0.relu\n",
      "backbone.base_model.model.6.0.downsample\n",
      "backbone.base_model.model.6.0.downsample.0\n",
      "backbone.base_model.model.6.0.downsample.1\n",
      "backbone.base_model.model.6.1\n",
      "backbone.base_model.model.6.1.conv1\n",
      "backbone.base_model.model.6.1.bn1\n",
      "backbone.base_model.model.6.1.conv2\n",
      "backbone.base_model.model.6.1.bn2\n",
      "backbone.base_model.model.6.1.conv3\n",
      "backbone.base_model.model.6.1.conv3.base_layer\n",
      "backbone.base_model.model.6.1.conv3.lora_dropout\n",
      "backbone.base_model.model.6.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.1.conv3.lora_A\n",
      "backbone.base_model.model.6.1.conv3.lora_A.default\n",
      "backbone.base_model.model.6.1.conv3.lora_B\n",
      "backbone.base_model.model.6.1.conv3.lora_B.default\n",
      "backbone.base_model.model.6.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.1.bn3\n",
      "backbone.base_model.model.6.1.relu\n",
      "backbone.base_model.model.6.2\n",
      "backbone.base_model.model.6.2.conv1\n",
      "backbone.base_model.model.6.2.bn1\n",
      "backbone.base_model.model.6.2.conv2\n",
      "backbone.base_model.model.6.2.bn2\n",
      "backbone.base_model.model.6.2.conv3\n",
      "backbone.base_model.model.6.2.conv3.base_layer\n",
      "backbone.base_model.model.6.2.conv3.lora_dropout\n",
      "backbone.base_model.model.6.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.2.conv3.lora_A\n",
      "backbone.base_model.model.6.2.conv3.lora_A.default\n",
      "backbone.base_model.model.6.2.conv3.lora_B\n",
      "backbone.base_model.model.6.2.conv3.lora_B.default\n",
      "backbone.base_model.model.6.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.2.bn3\n",
      "backbone.base_model.model.6.2.relu\n",
      "backbone.base_model.model.6.3\n",
      "backbone.base_model.model.6.3.conv1\n",
      "backbone.base_model.model.6.3.bn1\n",
      "backbone.base_model.model.6.3.conv2\n",
      "backbone.base_model.model.6.3.bn2\n",
      "backbone.base_model.model.6.3.conv3\n",
      "backbone.base_model.model.6.3.conv3.base_layer\n",
      "backbone.base_model.model.6.3.conv3.lora_dropout\n",
      "backbone.base_model.model.6.3.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.3.conv3.lora_A\n",
      "backbone.base_model.model.6.3.conv3.lora_A.default\n",
      "backbone.base_model.model.6.3.conv3.lora_B\n",
      "backbone.base_model.model.6.3.conv3.lora_B.default\n",
      "backbone.base_model.model.6.3.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.3.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.3.bn3\n",
      "backbone.base_model.model.6.3.relu\n",
      "backbone.base_model.model.6.4\n",
      "backbone.base_model.model.6.4.conv1\n",
      "backbone.base_model.model.6.4.bn1\n",
      "backbone.base_model.model.6.4.conv2\n",
      "backbone.base_model.model.6.4.bn2\n",
      "backbone.base_model.model.6.4.conv3\n",
      "backbone.base_model.model.6.4.conv3.base_layer\n",
      "backbone.base_model.model.6.4.conv3.lora_dropout\n",
      "backbone.base_model.model.6.4.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.4.conv3.lora_A\n",
      "backbone.base_model.model.6.4.conv3.lora_A.default\n",
      "backbone.base_model.model.6.4.conv3.lora_B\n",
      "backbone.base_model.model.6.4.conv3.lora_B.default\n",
      "backbone.base_model.model.6.4.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.4.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.4.bn3\n",
      "backbone.base_model.model.6.4.relu\n",
      "backbone.base_model.model.6.5\n",
      "backbone.base_model.model.6.5.conv1\n",
      "backbone.base_model.model.6.5.bn1\n",
      "backbone.base_model.model.6.5.conv2\n",
      "backbone.base_model.model.6.5.bn2\n",
      "backbone.base_model.model.6.5.conv3\n",
      "backbone.base_model.model.6.5.conv3.base_layer\n",
      "backbone.base_model.model.6.5.conv3.lora_dropout\n",
      "backbone.base_model.model.6.5.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.5.conv3.lora_A\n",
      "backbone.base_model.model.6.5.conv3.lora_A.default\n",
      "backbone.base_model.model.6.5.conv3.lora_B\n",
      "backbone.base_model.model.6.5.conv3.lora_B.default\n",
      "backbone.base_model.model.6.5.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.5.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.5.bn3\n",
      "backbone.base_model.model.6.5.relu\n",
      "backbone.base_model.model.7\n",
      "backbone.base_model.model.7.0\n",
      "backbone.base_model.model.7.0.conv1\n",
      "backbone.base_model.model.7.0.bn1\n",
      "backbone.base_model.model.7.0.conv2\n",
      "backbone.base_model.model.7.0.bn2\n",
      "backbone.base_model.model.7.0.conv3\n",
      "backbone.base_model.model.7.0.conv3.base_layer\n",
      "backbone.base_model.model.7.0.conv3.lora_dropout\n",
      "backbone.base_model.model.7.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.7.0.conv3.lora_A\n",
      "backbone.base_model.model.7.0.conv3.lora_A.default\n",
      "backbone.base_model.model.7.0.conv3.lora_B\n",
      "backbone.base_model.model.7.0.conv3.lora_B.default\n",
      "backbone.base_model.model.7.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.7.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.7.0.bn3\n",
      "backbone.base_model.model.7.0.relu\n",
      "backbone.base_model.model.7.0.downsample\n",
      "backbone.base_model.model.7.0.downsample.0\n",
      "backbone.base_model.model.7.0.downsample.1\n",
      "backbone.base_model.model.7.1\n",
      "backbone.base_model.model.7.1.conv1\n",
      "backbone.base_model.model.7.1.bn1\n",
      "backbone.base_model.model.7.1.conv2\n",
      "backbone.base_model.model.7.1.bn2\n",
      "backbone.base_model.model.7.1.conv3\n",
      "backbone.base_model.model.7.1.conv3.base_layer\n",
      "backbone.base_model.model.7.1.conv3.lora_dropout\n",
      "backbone.base_model.model.7.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.7.1.conv3.lora_A\n",
      "backbone.base_model.model.7.1.conv3.lora_A.default\n",
      "backbone.base_model.model.7.1.conv3.lora_B\n",
      "backbone.base_model.model.7.1.conv3.lora_B.default\n",
      "backbone.base_model.model.7.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.7.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.7.1.bn3\n",
      "backbone.base_model.model.7.1.relu\n",
      "backbone.base_model.model.7.2\n",
      "backbone.base_model.model.7.2.conv1\n",
      "backbone.base_model.model.7.2.bn1\n",
      "backbone.base_model.model.7.2.conv2\n",
      "backbone.base_model.model.7.2.bn2\n",
      "backbone.base_model.model.7.2.conv3\n",
      "backbone.base_model.model.7.2.conv3.base_layer\n",
      "backbone.base_model.model.7.2.conv3.lora_dropout\n",
      "backbone.base_model.model.7.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.7.2.conv3.lora_A\n",
      "backbone.base_model.model.7.2.conv3.lora_A.default\n",
      "backbone.base_model.model.7.2.conv3.lora_B\n",
      "backbone.base_model.model.7.2.conv3.lora_B.default\n",
      "backbone.base_model.model.7.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.7.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.7.2.bn3\n",
      "backbone.base_model.model.7.2.relu\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.0.convs\n",
      "classifier.0.convs.0\n",
      "classifier.0.convs.0.0\n",
      "classifier.0.convs.0.1\n",
      "classifier.0.convs.0.2\n",
      "classifier.0.convs.1\n",
      "classifier.0.convs.1.0\n",
      "classifier.0.convs.1.1\n",
      "classifier.0.convs.1.2\n",
      "classifier.0.convs.2\n",
      "classifier.0.convs.2.0\n",
      "classifier.0.convs.2.1\n",
      "classifier.0.convs.2.2\n",
      "classifier.0.convs.3\n",
      "classifier.0.convs.3.0\n",
      "classifier.0.convs.3.1\n",
      "classifier.0.convs.3.2\n",
      "classifier.0.convs.4\n",
      "classifier.0.convs.4.0\n",
      "classifier.0.convs.4.1\n",
      "classifier.0.convs.4.2\n",
      "classifier.0.convs.4.3\n",
      "classifier.0.project\n",
      "classifier.0.project.0\n",
      "classifier.0.project.1\n",
      "classifier.0.project.2\n",
      "classifier.0.project.3\n",
      "classifier.1\n",
      "classifier.2\n",
      "classifier.3\n",
      "classifier.4\n",
      "CustomDeepLabV3(\n",
      "  (backbone): PeftModel(\n",
      "    (base_model): LoraModel(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# segmentation_model 1.1: res50 + LoRA(conv2) + DeepLabV3\n",
    "class CustomDeepLabV3(torch.nn.Module):\n",
    "    def __init__(self, backbone, classifier):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        #print(\"size after downsampling\", features.shape)\n",
    "        x = self.classifier(features)\n",
    "        #print(\"size after segmentation head\", x.shape)\n",
    "        # spatial dimensions of this map are smaller than the original input image due to the downsampling operations in the backbone.\n",
    "        # We can upsample the output to the size of the input image using interpolation\n",
    "        x = torch.nn.functional.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        #print(\"size after upsampling\", x.shape)\n",
    "        return {'out': x}\n",
    "\n",
    "backbone = models.resnet50(pretrained=True)\n",
    "backbone = torch.nn.Sequential(*(list(backbone.children())[:-2])) # remove the last two layers\n",
    "# backbone.add_module('avgpool', torch.nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "\n",
    "num_classes = 20\n",
    "# the segmentation head is responsible for making the final pixel-wise predictions\n",
    "segmentation_head = DeepLabHead(2048, num_classes)\n",
    "# 2048 is the number of output channels in the resnet50 backbone\n",
    "\n",
    "# Then use your custom model instead of the original one\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"conv3\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"],\n",
    ")\n",
    "backbone = get_peft_model(backbone, config)\n",
    "\n",
    "model = CustomDeepLabV3(backbone, segmentation_head)\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T02:16:47.969656Z",
     "start_time": "2024-04-27T02:16:44.728830Z"
    }
   },
   "id": "b62fee2ae7ef4265"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 17036820 || all params: 40544852 || trainable%: 42.02\n",
      "\n",
      "backbone\n",
      "backbone.base_model\n",
      "backbone.base_model.model\n",
      "backbone.base_model.model.0\n",
      "backbone.base_model.model.1\n",
      "backbone.base_model.model.2\n",
      "backbone.base_model.model.3\n",
      "backbone.base_model.model.4\n",
      "backbone.base_model.model.4.0\n",
      "backbone.base_model.model.4.0.conv1\n",
      "backbone.base_model.model.4.0.bn1\n",
      "backbone.base_model.model.4.0.conv2\n",
      "backbone.base_model.model.4.0.conv2.base_layer\n",
      "backbone.base_model.model.4.0.conv2.lora_dropout\n",
      "backbone.base_model.model.4.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.4.0.conv2.lora_A\n",
      "backbone.base_model.model.4.0.conv2.lora_A.default\n",
      "backbone.base_model.model.4.0.conv2.lora_B\n",
      "backbone.base_model.model.4.0.conv2.lora_B.default\n",
      "backbone.base_model.model.4.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.4.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.4.0.bn2\n",
      "backbone.base_model.model.4.0.conv3\n",
      "backbone.base_model.model.4.0.conv3.base_layer\n",
      "backbone.base_model.model.4.0.conv3.lora_dropout\n",
      "backbone.base_model.model.4.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.4.0.conv3.lora_A\n",
      "backbone.base_model.model.4.0.conv3.lora_A.default\n",
      "backbone.base_model.model.4.0.conv3.lora_B\n",
      "backbone.base_model.model.4.0.conv3.lora_B.default\n",
      "backbone.base_model.model.4.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.4.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.4.0.bn3\n",
      "backbone.base_model.model.4.0.relu\n",
      "backbone.base_model.model.4.0.downsample\n",
      "backbone.base_model.model.4.0.downsample.0\n",
      "backbone.base_model.model.4.0.downsample.1\n",
      "backbone.base_model.model.4.1\n",
      "backbone.base_model.model.4.1.conv1\n",
      "backbone.base_model.model.4.1.bn1\n",
      "backbone.base_model.model.4.1.conv2\n",
      "backbone.base_model.model.4.1.conv2.base_layer\n",
      "backbone.base_model.model.4.1.conv2.lora_dropout\n",
      "backbone.base_model.model.4.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.4.1.conv2.lora_A\n",
      "backbone.base_model.model.4.1.conv2.lora_A.default\n",
      "backbone.base_model.model.4.1.conv2.lora_B\n",
      "backbone.base_model.model.4.1.conv2.lora_B.default\n",
      "backbone.base_model.model.4.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.4.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.4.1.bn2\n",
      "backbone.base_model.model.4.1.conv3\n",
      "backbone.base_model.model.4.1.conv3.base_layer\n",
      "backbone.base_model.model.4.1.conv3.lora_dropout\n",
      "backbone.base_model.model.4.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.4.1.conv3.lora_A\n",
      "backbone.base_model.model.4.1.conv3.lora_A.default\n",
      "backbone.base_model.model.4.1.conv3.lora_B\n",
      "backbone.base_model.model.4.1.conv3.lora_B.default\n",
      "backbone.base_model.model.4.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.4.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.4.1.bn3\n",
      "backbone.base_model.model.4.1.relu\n",
      "backbone.base_model.model.4.2\n",
      "backbone.base_model.model.4.2.conv1\n",
      "backbone.base_model.model.4.2.bn1\n",
      "backbone.base_model.model.4.2.conv2\n",
      "backbone.base_model.model.4.2.conv2.base_layer\n",
      "backbone.base_model.model.4.2.conv2.lora_dropout\n",
      "backbone.base_model.model.4.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.4.2.conv2.lora_A\n",
      "backbone.base_model.model.4.2.conv2.lora_A.default\n",
      "backbone.base_model.model.4.2.conv2.lora_B\n",
      "backbone.base_model.model.4.2.conv2.lora_B.default\n",
      "backbone.base_model.model.4.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.4.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.4.2.bn2\n",
      "backbone.base_model.model.4.2.conv3\n",
      "backbone.base_model.model.4.2.conv3.base_layer\n",
      "backbone.base_model.model.4.2.conv3.lora_dropout\n",
      "backbone.base_model.model.4.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.4.2.conv3.lora_A\n",
      "backbone.base_model.model.4.2.conv3.lora_A.default\n",
      "backbone.base_model.model.4.2.conv3.lora_B\n",
      "backbone.base_model.model.4.2.conv3.lora_B.default\n",
      "backbone.base_model.model.4.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.4.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.4.2.bn3\n",
      "backbone.base_model.model.4.2.relu\n",
      "backbone.base_model.model.5\n",
      "backbone.base_model.model.5.0\n",
      "backbone.base_model.model.5.0.conv1\n",
      "backbone.base_model.model.5.0.bn1\n",
      "backbone.base_model.model.5.0.conv2\n",
      "backbone.base_model.model.5.0.conv2.base_layer\n",
      "backbone.base_model.model.5.0.conv2.lora_dropout\n",
      "backbone.base_model.model.5.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.0.conv2.lora_A\n",
      "backbone.base_model.model.5.0.conv2.lora_A.default\n",
      "backbone.base_model.model.5.0.conv2.lora_B\n",
      "backbone.base_model.model.5.0.conv2.lora_B.default\n",
      "backbone.base_model.model.5.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.0.bn2\n",
      "backbone.base_model.model.5.0.conv3\n",
      "backbone.base_model.model.5.0.conv3.base_layer\n",
      "backbone.base_model.model.5.0.conv3.lora_dropout\n",
      "backbone.base_model.model.5.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.0.conv3.lora_A\n",
      "backbone.base_model.model.5.0.conv3.lora_A.default\n",
      "backbone.base_model.model.5.0.conv3.lora_B\n",
      "backbone.base_model.model.5.0.conv3.lora_B.default\n",
      "backbone.base_model.model.5.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.0.bn3\n",
      "backbone.base_model.model.5.0.relu\n",
      "backbone.base_model.model.5.0.downsample\n",
      "backbone.base_model.model.5.0.downsample.0\n",
      "backbone.base_model.model.5.0.downsample.1\n",
      "backbone.base_model.model.5.1\n",
      "backbone.base_model.model.5.1.conv1\n",
      "backbone.base_model.model.5.1.bn1\n",
      "backbone.base_model.model.5.1.conv2\n",
      "backbone.base_model.model.5.1.conv2.base_layer\n",
      "backbone.base_model.model.5.1.conv2.lora_dropout\n",
      "backbone.base_model.model.5.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.1.conv2.lora_A\n",
      "backbone.base_model.model.5.1.conv2.lora_A.default\n",
      "backbone.base_model.model.5.1.conv2.lora_B\n",
      "backbone.base_model.model.5.1.conv2.lora_B.default\n",
      "backbone.base_model.model.5.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.1.bn2\n",
      "backbone.base_model.model.5.1.conv3\n",
      "backbone.base_model.model.5.1.conv3.base_layer\n",
      "backbone.base_model.model.5.1.conv3.lora_dropout\n",
      "backbone.base_model.model.5.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.1.conv3.lora_A\n",
      "backbone.base_model.model.5.1.conv3.lora_A.default\n",
      "backbone.base_model.model.5.1.conv3.lora_B\n",
      "backbone.base_model.model.5.1.conv3.lora_B.default\n",
      "backbone.base_model.model.5.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.1.bn3\n",
      "backbone.base_model.model.5.1.relu\n",
      "backbone.base_model.model.5.2\n",
      "backbone.base_model.model.5.2.conv1\n",
      "backbone.base_model.model.5.2.bn1\n",
      "backbone.base_model.model.5.2.conv2\n",
      "backbone.base_model.model.5.2.conv2.base_layer\n",
      "backbone.base_model.model.5.2.conv2.lora_dropout\n",
      "backbone.base_model.model.5.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.2.conv2.lora_A\n",
      "backbone.base_model.model.5.2.conv2.lora_A.default\n",
      "backbone.base_model.model.5.2.conv2.lora_B\n",
      "backbone.base_model.model.5.2.conv2.lora_B.default\n",
      "backbone.base_model.model.5.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.2.bn2\n",
      "backbone.base_model.model.5.2.conv3\n",
      "backbone.base_model.model.5.2.conv3.base_layer\n",
      "backbone.base_model.model.5.2.conv3.lora_dropout\n",
      "backbone.base_model.model.5.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.2.conv3.lora_A\n",
      "backbone.base_model.model.5.2.conv3.lora_A.default\n",
      "backbone.base_model.model.5.2.conv3.lora_B\n",
      "backbone.base_model.model.5.2.conv3.lora_B.default\n",
      "backbone.base_model.model.5.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.2.bn3\n",
      "backbone.base_model.model.5.2.relu\n",
      "backbone.base_model.model.5.3\n",
      "backbone.base_model.model.5.3.conv1\n",
      "backbone.base_model.model.5.3.bn1\n",
      "backbone.base_model.model.5.3.conv2\n",
      "backbone.base_model.model.5.3.conv2.base_layer\n",
      "backbone.base_model.model.5.3.conv2.lora_dropout\n",
      "backbone.base_model.model.5.3.conv2.lora_dropout.default\n",
      "backbone.base_model.model.5.3.conv2.lora_A\n",
      "backbone.base_model.model.5.3.conv2.lora_A.default\n",
      "backbone.base_model.model.5.3.conv2.lora_B\n",
      "backbone.base_model.model.5.3.conv2.lora_B.default\n",
      "backbone.base_model.model.5.3.conv2.lora_embedding_A\n",
      "backbone.base_model.model.5.3.conv2.lora_embedding_B\n",
      "backbone.base_model.model.5.3.bn2\n",
      "backbone.base_model.model.5.3.conv3\n",
      "backbone.base_model.model.5.3.conv3.base_layer\n",
      "backbone.base_model.model.5.3.conv3.lora_dropout\n",
      "backbone.base_model.model.5.3.conv3.lora_dropout.default\n",
      "backbone.base_model.model.5.3.conv3.lora_A\n",
      "backbone.base_model.model.5.3.conv3.lora_A.default\n",
      "backbone.base_model.model.5.3.conv3.lora_B\n",
      "backbone.base_model.model.5.3.conv3.lora_B.default\n",
      "backbone.base_model.model.5.3.conv3.lora_embedding_A\n",
      "backbone.base_model.model.5.3.conv3.lora_embedding_B\n",
      "backbone.base_model.model.5.3.bn3\n",
      "backbone.base_model.model.5.3.relu\n",
      "backbone.base_model.model.6\n",
      "backbone.base_model.model.6.0\n",
      "backbone.base_model.model.6.0.conv1\n",
      "backbone.base_model.model.6.0.bn1\n",
      "backbone.base_model.model.6.0.conv2\n",
      "backbone.base_model.model.6.0.conv2.base_layer\n",
      "backbone.base_model.model.6.0.conv2.lora_dropout\n",
      "backbone.base_model.model.6.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.0.conv2.lora_A\n",
      "backbone.base_model.model.6.0.conv2.lora_A.default\n",
      "backbone.base_model.model.6.0.conv2.lora_B\n",
      "backbone.base_model.model.6.0.conv2.lora_B.default\n",
      "backbone.base_model.model.6.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.0.bn2\n",
      "backbone.base_model.model.6.0.conv3\n",
      "backbone.base_model.model.6.0.conv3.base_layer\n",
      "backbone.base_model.model.6.0.conv3.lora_dropout\n",
      "backbone.base_model.model.6.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.0.conv3.lora_A\n",
      "backbone.base_model.model.6.0.conv3.lora_A.default\n",
      "backbone.base_model.model.6.0.conv3.lora_B\n",
      "backbone.base_model.model.6.0.conv3.lora_B.default\n",
      "backbone.base_model.model.6.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.0.bn3\n",
      "backbone.base_model.model.6.0.relu\n",
      "backbone.base_model.model.6.0.downsample\n",
      "backbone.base_model.model.6.0.downsample.0\n",
      "backbone.base_model.model.6.0.downsample.1\n",
      "backbone.base_model.model.6.1\n",
      "backbone.base_model.model.6.1.conv1\n",
      "backbone.base_model.model.6.1.bn1\n",
      "backbone.base_model.model.6.1.conv2\n",
      "backbone.base_model.model.6.1.conv2.base_layer\n",
      "backbone.base_model.model.6.1.conv2.lora_dropout\n",
      "backbone.base_model.model.6.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.1.conv2.lora_A\n",
      "backbone.base_model.model.6.1.conv2.lora_A.default\n",
      "backbone.base_model.model.6.1.conv2.lora_B\n",
      "backbone.base_model.model.6.1.conv2.lora_B.default\n",
      "backbone.base_model.model.6.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.1.bn2\n",
      "backbone.base_model.model.6.1.conv3\n",
      "backbone.base_model.model.6.1.conv3.base_layer\n",
      "backbone.base_model.model.6.1.conv3.lora_dropout\n",
      "backbone.base_model.model.6.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.1.conv3.lora_A\n",
      "backbone.base_model.model.6.1.conv3.lora_A.default\n",
      "backbone.base_model.model.6.1.conv3.lora_B\n",
      "backbone.base_model.model.6.1.conv3.lora_B.default\n",
      "backbone.base_model.model.6.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.1.bn3\n",
      "backbone.base_model.model.6.1.relu\n",
      "backbone.base_model.model.6.2\n",
      "backbone.base_model.model.6.2.conv1\n",
      "backbone.base_model.model.6.2.bn1\n",
      "backbone.base_model.model.6.2.conv2\n",
      "backbone.base_model.model.6.2.conv2.base_layer\n",
      "backbone.base_model.model.6.2.conv2.lora_dropout\n",
      "backbone.base_model.model.6.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.2.conv2.lora_A\n",
      "backbone.base_model.model.6.2.conv2.lora_A.default\n",
      "backbone.base_model.model.6.2.conv2.lora_B\n",
      "backbone.base_model.model.6.2.conv2.lora_B.default\n",
      "backbone.base_model.model.6.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.2.bn2\n",
      "backbone.base_model.model.6.2.conv3\n",
      "backbone.base_model.model.6.2.conv3.base_layer\n",
      "backbone.base_model.model.6.2.conv3.lora_dropout\n",
      "backbone.base_model.model.6.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.2.conv3.lora_A\n",
      "backbone.base_model.model.6.2.conv3.lora_A.default\n",
      "backbone.base_model.model.6.2.conv3.lora_B\n",
      "backbone.base_model.model.6.2.conv3.lora_B.default\n",
      "backbone.base_model.model.6.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.2.bn3\n",
      "backbone.base_model.model.6.2.relu\n",
      "backbone.base_model.model.6.3\n",
      "backbone.base_model.model.6.3.conv1\n",
      "backbone.base_model.model.6.3.bn1\n",
      "backbone.base_model.model.6.3.conv2\n",
      "backbone.base_model.model.6.3.conv2.base_layer\n",
      "backbone.base_model.model.6.3.conv2.lora_dropout\n",
      "backbone.base_model.model.6.3.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.3.conv2.lora_A\n",
      "backbone.base_model.model.6.3.conv2.lora_A.default\n",
      "backbone.base_model.model.6.3.conv2.lora_B\n",
      "backbone.base_model.model.6.3.conv2.lora_B.default\n",
      "backbone.base_model.model.6.3.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.3.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.3.bn2\n",
      "backbone.base_model.model.6.3.conv3\n",
      "backbone.base_model.model.6.3.conv3.base_layer\n",
      "backbone.base_model.model.6.3.conv3.lora_dropout\n",
      "backbone.base_model.model.6.3.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.3.conv3.lora_A\n",
      "backbone.base_model.model.6.3.conv3.lora_A.default\n",
      "backbone.base_model.model.6.3.conv3.lora_B\n",
      "backbone.base_model.model.6.3.conv3.lora_B.default\n",
      "backbone.base_model.model.6.3.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.3.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.3.bn3\n",
      "backbone.base_model.model.6.3.relu\n",
      "backbone.base_model.model.6.4\n",
      "backbone.base_model.model.6.4.conv1\n",
      "backbone.base_model.model.6.4.bn1\n",
      "backbone.base_model.model.6.4.conv2\n",
      "backbone.base_model.model.6.4.conv2.base_layer\n",
      "backbone.base_model.model.6.4.conv2.lora_dropout\n",
      "backbone.base_model.model.6.4.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.4.conv2.lora_A\n",
      "backbone.base_model.model.6.4.conv2.lora_A.default\n",
      "backbone.base_model.model.6.4.conv2.lora_B\n",
      "backbone.base_model.model.6.4.conv2.lora_B.default\n",
      "backbone.base_model.model.6.4.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.4.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.4.bn2\n",
      "backbone.base_model.model.6.4.conv3\n",
      "backbone.base_model.model.6.4.conv3.base_layer\n",
      "backbone.base_model.model.6.4.conv3.lora_dropout\n",
      "backbone.base_model.model.6.4.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.4.conv3.lora_A\n",
      "backbone.base_model.model.6.4.conv3.lora_A.default\n",
      "backbone.base_model.model.6.4.conv3.lora_B\n",
      "backbone.base_model.model.6.4.conv3.lora_B.default\n",
      "backbone.base_model.model.6.4.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.4.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.4.bn3\n",
      "backbone.base_model.model.6.4.relu\n",
      "backbone.base_model.model.6.5\n",
      "backbone.base_model.model.6.5.conv1\n",
      "backbone.base_model.model.6.5.bn1\n",
      "backbone.base_model.model.6.5.conv2\n",
      "backbone.base_model.model.6.5.conv2.base_layer\n",
      "backbone.base_model.model.6.5.conv2.lora_dropout\n",
      "backbone.base_model.model.6.5.conv2.lora_dropout.default\n",
      "backbone.base_model.model.6.5.conv2.lora_A\n",
      "backbone.base_model.model.6.5.conv2.lora_A.default\n",
      "backbone.base_model.model.6.5.conv2.lora_B\n",
      "backbone.base_model.model.6.5.conv2.lora_B.default\n",
      "backbone.base_model.model.6.5.conv2.lora_embedding_A\n",
      "backbone.base_model.model.6.5.conv2.lora_embedding_B\n",
      "backbone.base_model.model.6.5.bn2\n",
      "backbone.base_model.model.6.5.conv3\n",
      "backbone.base_model.model.6.5.conv3.base_layer\n",
      "backbone.base_model.model.6.5.conv3.lora_dropout\n",
      "backbone.base_model.model.6.5.conv3.lora_dropout.default\n",
      "backbone.base_model.model.6.5.conv3.lora_A\n",
      "backbone.base_model.model.6.5.conv3.lora_A.default\n",
      "backbone.base_model.model.6.5.conv3.lora_B\n",
      "backbone.base_model.model.6.5.conv3.lora_B.default\n",
      "backbone.base_model.model.6.5.conv3.lora_embedding_A\n",
      "backbone.base_model.model.6.5.conv3.lora_embedding_B\n",
      "backbone.base_model.model.6.5.bn3\n",
      "backbone.base_model.model.6.5.relu\n",
      "backbone.base_model.model.7\n",
      "backbone.base_model.model.7.0\n",
      "backbone.base_model.model.7.0.conv1\n",
      "backbone.base_model.model.7.0.bn1\n",
      "backbone.base_model.model.7.0.conv2\n",
      "backbone.base_model.model.7.0.conv2.base_layer\n",
      "backbone.base_model.model.7.0.conv2.lora_dropout\n",
      "backbone.base_model.model.7.0.conv2.lora_dropout.default\n",
      "backbone.base_model.model.7.0.conv2.lora_A\n",
      "backbone.base_model.model.7.0.conv2.lora_A.default\n",
      "backbone.base_model.model.7.0.conv2.lora_B\n",
      "backbone.base_model.model.7.0.conv2.lora_B.default\n",
      "backbone.base_model.model.7.0.conv2.lora_embedding_A\n",
      "backbone.base_model.model.7.0.conv2.lora_embedding_B\n",
      "backbone.base_model.model.7.0.bn2\n",
      "backbone.base_model.model.7.0.conv3\n",
      "backbone.base_model.model.7.0.conv3.base_layer\n",
      "backbone.base_model.model.7.0.conv3.lora_dropout\n",
      "backbone.base_model.model.7.0.conv3.lora_dropout.default\n",
      "backbone.base_model.model.7.0.conv3.lora_A\n",
      "backbone.base_model.model.7.0.conv3.lora_A.default\n",
      "backbone.base_model.model.7.0.conv3.lora_B\n",
      "backbone.base_model.model.7.0.conv3.lora_B.default\n",
      "backbone.base_model.model.7.0.conv3.lora_embedding_A\n",
      "backbone.base_model.model.7.0.conv3.lora_embedding_B\n",
      "backbone.base_model.model.7.0.bn3\n",
      "backbone.base_model.model.7.0.relu\n",
      "backbone.base_model.model.7.0.downsample\n",
      "backbone.base_model.model.7.0.downsample.0\n",
      "backbone.base_model.model.7.0.downsample.1\n",
      "backbone.base_model.model.7.1\n",
      "backbone.base_model.model.7.1.conv1\n",
      "backbone.base_model.model.7.1.bn1\n",
      "backbone.base_model.model.7.1.conv2\n",
      "backbone.base_model.model.7.1.conv2.base_layer\n",
      "backbone.base_model.model.7.1.conv2.lora_dropout\n",
      "backbone.base_model.model.7.1.conv2.lora_dropout.default\n",
      "backbone.base_model.model.7.1.conv2.lora_A\n",
      "backbone.base_model.model.7.1.conv2.lora_A.default\n",
      "backbone.base_model.model.7.1.conv2.lora_B\n",
      "backbone.base_model.model.7.1.conv2.lora_B.default\n",
      "backbone.base_model.model.7.1.conv2.lora_embedding_A\n",
      "backbone.base_model.model.7.1.conv2.lora_embedding_B\n",
      "backbone.base_model.model.7.1.bn2\n",
      "backbone.base_model.model.7.1.conv3\n",
      "backbone.base_model.model.7.1.conv3.base_layer\n",
      "backbone.base_model.model.7.1.conv3.lora_dropout\n",
      "backbone.base_model.model.7.1.conv3.lora_dropout.default\n",
      "backbone.base_model.model.7.1.conv3.lora_A\n",
      "backbone.base_model.model.7.1.conv3.lora_A.default\n",
      "backbone.base_model.model.7.1.conv3.lora_B\n",
      "backbone.base_model.model.7.1.conv3.lora_B.default\n",
      "backbone.base_model.model.7.1.conv3.lora_embedding_A\n",
      "backbone.base_model.model.7.1.conv3.lora_embedding_B\n",
      "backbone.base_model.model.7.1.bn3\n",
      "backbone.base_model.model.7.1.relu\n",
      "backbone.base_model.model.7.2\n",
      "backbone.base_model.model.7.2.conv1\n",
      "backbone.base_model.model.7.2.bn1\n",
      "backbone.base_model.model.7.2.conv2\n",
      "backbone.base_model.model.7.2.conv2.base_layer\n",
      "backbone.base_model.model.7.2.conv2.lora_dropout\n",
      "backbone.base_model.model.7.2.conv2.lora_dropout.default\n",
      "backbone.base_model.model.7.2.conv2.lora_A\n",
      "backbone.base_model.model.7.2.conv2.lora_A.default\n",
      "backbone.base_model.model.7.2.conv2.lora_B\n",
      "backbone.base_model.model.7.2.conv2.lora_B.default\n",
      "backbone.base_model.model.7.2.conv2.lora_embedding_A\n",
      "backbone.base_model.model.7.2.conv2.lora_embedding_B\n",
      "backbone.base_model.model.7.2.bn2\n",
      "backbone.base_model.model.7.2.conv3\n",
      "backbone.base_model.model.7.2.conv3.base_layer\n",
      "backbone.base_model.model.7.2.conv3.lora_dropout\n",
      "backbone.base_model.model.7.2.conv3.lora_dropout.default\n",
      "backbone.base_model.model.7.2.conv3.lora_A\n",
      "backbone.base_model.model.7.2.conv3.lora_A.default\n",
      "backbone.base_model.model.7.2.conv3.lora_B\n",
      "backbone.base_model.model.7.2.conv3.lora_B.default\n",
      "backbone.base_model.model.7.2.conv3.lora_embedding_A\n",
      "backbone.base_model.model.7.2.conv3.lora_embedding_B\n",
      "backbone.base_model.model.7.2.bn3\n",
      "backbone.base_model.model.7.2.relu\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.0.convs\n",
      "classifier.0.convs.0\n",
      "classifier.0.convs.0.0\n",
      "classifier.0.convs.0.1\n",
      "classifier.0.convs.0.2\n",
      "classifier.0.convs.1\n",
      "classifier.0.convs.1.0\n",
      "classifier.0.convs.1.1\n",
      "classifier.0.convs.1.2\n",
      "classifier.0.convs.2\n",
      "classifier.0.convs.2.0\n",
      "classifier.0.convs.2.1\n",
      "classifier.0.convs.2.2\n",
      "classifier.0.convs.3\n",
      "classifier.0.convs.3.0\n",
      "classifier.0.convs.3.1\n",
      "classifier.0.convs.3.2\n",
      "classifier.0.convs.4\n",
      "classifier.0.convs.4.0\n",
      "classifier.0.convs.4.1\n",
      "classifier.0.convs.4.2\n",
      "classifier.0.convs.4.3\n",
      "classifier.0.project\n",
      "classifier.0.project.0\n",
      "classifier.0.project.1\n",
      "classifier.0.project.2\n",
      "classifier.0.project.3\n",
      "classifier.1\n",
      "classifier.2\n",
      "classifier.3\n",
      "classifier.4\n",
      "CustomDeepLabV3(\n",
      "  (backbone): PeftModel(\n",
      "    (base_model): LoraModel(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): lora.Conv2d(\n",
      "              (base_layer): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Conv2d(16, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# segmentation_model 1.3: res50 + LoRA(conv2, conv3) + DeepLabV3\n",
    "class CustomDeepLabV3(torch.nn.Module):\n",
    "    def __init__(self, backbone, classifier):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        #print(\"size after downsampling\", features.shape)\n",
    "        x = self.classifier(features)\n",
    "        #print(\"size after segmentation head\", x.shape)\n",
    "        # spatial dimensions of this map are smaller than the original input image due to the downsampling operations in the backbone.\n",
    "        # We can upsample the output to the size of the input image using interpolation\n",
    "        x = torch.nn.functional.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        #print(\"size after upsampling\", x.shape)\n",
    "        return {'out': x}\n",
    "\n",
    "backbone = models.resnet50(pretrained=True)\n",
    "backbone = torch.nn.Sequential(*(list(backbone.children())[:-2])) # remove the last two layers\n",
    "# backbone.add_module('avgpool', torch.nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "\n",
    "num_classes = 20\n",
    "# the segmentation head is responsible for making the final pixel-wise predictions\n",
    "segmentation_head = DeepLabHead(2048, num_classes)\n",
    "# 2048 is the number of output channels in the resnet50 backbone\n",
    "\n",
    "# Then use your custom model instead of the original one\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"conv2\",\"conv3\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"],\n",
    ")\n",
    "backbone = get_peft_model(backbone, config)\n",
    "\n",
    "model = CustomDeepLabV3(backbone, segmentation_head)\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T16:14:39.305458Z",
     "start_time": "2024-04-27T16:14:37.743165Z"
    }
   },
   "id": "974711265686b2ac"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85800194 || all params: 85800194 || trainable%: 100.00\n",
      "\n",
      "vit\n",
      "vit.embeddings\n",
      "vit.embeddings.patch_embeddings\n",
      "vit.embeddings.patch_embeddings.projection\n",
      "vit.embeddings.dropout\n",
      "vit.encoder\n",
      "vit.encoder.layer\n",
      "vit.encoder.layer.0\n",
      "vit.encoder.layer.0.attention\n",
      "vit.encoder.layer.0.attention.attention\n",
      "vit.encoder.layer.0.attention.attention.query\n",
      "vit.encoder.layer.0.attention.attention.key\n",
      "vit.encoder.layer.0.attention.attention.value\n",
      "vit.encoder.layer.0.attention.attention.dropout\n",
      "vit.encoder.layer.0.attention.output\n",
      "vit.encoder.layer.0.attention.output.dense\n",
      "vit.encoder.layer.0.attention.output.dropout\n",
      "vit.encoder.layer.0.intermediate\n",
      "vit.encoder.layer.0.intermediate.dense\n",
      "vit.encoder.layer.0.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.0.output\n",
      "vit.encoder.layer.0.output.dense\n",
      "vit.encoder.layer.0.output.dropout\n",
      "vit.encoder.layer.0.layernorm_before\n",
      "vit.encoder.layer.0.layernorm_after\n",
      "vit.encoder.layer.1\n",
      "vit.encoder.layer.1.attention\n",
      "vit.encoder.layer.1.attention.attention\n",
      "vit.encoder.layer.1.attention.attention.query\n",
      "vit.encoder.layer.1.attention.attention.key\n",
      "vit.encoder.layer.1.attention.attention.value\n",
      "vit.encoder.layer.1.attention.attention.dropout\n",
      "vit.encoder.layer.1.attention.output\n",
      "vit.encoder.layer.1.attention.output.dense\n",
      "vit.encoder.layer.1.attention.output.dropout\n",
      "vit.encoder.layer.1.intermediate\n",
      "vit.encoder.layer.1.intermediate.dense\n",
      "vit.encoder.layer.1.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.1.output\n",
      "vit.encoder.layer.1.output.dense\n",
      "vit.encoder.layer.1.output.dropout\n",
      "vit.encoder.layer.1.layernorm_before\n",
      "vit.encoder.layer.1.layernorm_after\n",
      "vit.encoder.layer.2\n",
      "vit.encoder.layer.2.attention\n",
      "vit.encoder.layer.2.attention.attention\n",
      "vit.encoder.layer.2.attention.attention.query\n",
      "vit.encoder.layer.2.attention.attention.key\n",
      "vit.encoder.layer.2.attention.attention.value\n",
      "vit.encoder.layer.2.attention.attention.dropout\n",
      "vit.encoder.layer.2.attention.output\n",
      "vit.encoder.layer.2.attention.output.dense\n",
      "vit.encoder.layer.2.attention.output.dropout\n",
      "vit.encoder.layer.2.intermediate\n",
      "vit.encoder.layer.2.intermediate.dense\n",
      "vit.encoder.layer.2.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.2.output\n",
      "vit.encoder.layer.2.output.dense\n",
      "vit.encoder.layer.2.output.dropout\n",
      "vit.encoder.layer.2.layernorm_before\n",
      "vit.encoder.layer.2.layernorm_after\n",
      "vit.encoder.layer.3\n",
      "vit.encoder.layer.3.attention\n",
      "vit.encoder.layer.3.attention.attention\n",
      "vit.encoder.layer.3.attention.attention.query\n",
      "vit.encoder.layer.3.attention.attention.key\n",
      "vit.encoder.layer.3.attention.attention.value\n",
      "vit.encoder.layer.3.attention.attention.dropout\n",
      "vit.encoder.layer.3.attention.output\n",
      "vit.encoder.layer.3.attention.output.dense\n",
      "vit.encoder.layer.3.attention.output.dropout\n",
      "vit.encoder.layer.3.intermediate\n",
      "vit.encoder.layer.3.intermediate.dense\n",
      "vit.encoder.layer.3.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.3.output\n",
      "vit.encoder.layer.3.output.dense\n",
      "vit.encoder.layer.3.output.dropout\n",
      "vit.encoder.layer.3.layernorm_before\n",
      "vit.encoder.layer.3.layernorm_after\n",
      "vit.encoder.layer.4\n",
      "vit.encoder.layer.4.attention\n",
      "vit.encoder.layer.4.attention.attention\n",
      "vit.encoder.layer.4.attention.attention.query\n",
      "vit.encoder.layer.4.attention.attention.key\n",
      "vit.encoder.layer.4.attention.attention.value\n",
      "vit.encoder.layer.4.attention.attention.dropout\n",
      "vit.encoder.layer.4.attention.output\n",
      "vit.encoder.layer.4.attention.output.dense\n",
      "vit.encoder.layer.4.attention.output.dropout\n",
      "vit.encoder.layer.4.intermediate\n",
      "vit.encoder.layer.4.intermediate.dense\n",
      "vit.encoder.layer.4.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.4.output\n",
      "vit.encoder.layer.4.output.dense\n",
      "vit.encoder.layer.4.output.dropout\n",
      "vit.encoder.layer.4.layernorm_before\n",
      "vit.encoder.layer.4.layernorm_after\n",
      "vit.encoder.layer.5\n",
      "vit.encoder.layer.5.attention\n",
      "vit.encoder.layer.5.attention.attention\n",
      "vit.encoder.layer.5.attention.attention.query\n",
      "vit.encoder.layer.5.attention.attention.key\n",
      "vit.encoder.layer.5.attention.attention.value\n",
      "vit.encoder.layer.5.attention.attention.dropout\n",
      "vit.encoder.layer.5.attention.output\n",
      "vit.encoder.layer.5.attention.output.dense\n",
      "vit.encoder.layer.5.attention.output.dropout\n",
      "vit.encoder.layer.5.intermediate\n",
      "vit.encoder.layer.5.intermediate.dense\n",
      "vit.encoder.layer.5.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.5.output\n",
      "vit.encoder.layer.5.output.dense\n",
      "vit.encoder.layer.5.output.dropout\n",
      "vit.encoder.layer.5.layernorm_before\n",
      "vit.encoder.layer.5.layernorm_after\n",
      "vit.encoder.layer.6\n",
      "vit.encoder.layer.6.attention\n",
      "vit.encoder.layer.6.attention.attention\n",
      "vit.encoder.layer.6.attention.attention.query\n",
      "vit.encoder.layer.6.attention.attention.key\n",
      "vit.encoder.layer.6.attention.attention.value\n",
      "vit.encoder.layer.6.attention.attention.dropout\n",
      "vit.encoder.layer.6.attention.output\n",
      "vit.encoder.layer.6.attention.output.dense\n",
      "vit.encoder.layer.6.attention.output.dropout\n",
      "vit.encoder.layer.6.intermediate\n",
      "vit.encoder.layer.6.intermediate.dense\n",
      "vit.encoder.layer.6.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.6.output\n",
      "vit.encoder.layer.6.output.dense\n",
      "vit.encoder.layer.6.output.dropout\n",
      "vit.encoder.layer.6.layernorm_before\n",
      "vit.encoder.layer.6.layernorm_after\n",
      "vit.encoder.layer.7\n",
      "vit.encoder.layer.7.attention\n",
      "vit.encoder.layer.7.attention.attention\n",
      "vit.encoder.layer.7.attention.attention.query\n",
      "vit.encoder.layer.7.attention.attention.key\n",
      "vit.encoder.layer.7.attention.attention.value\n",
      "vit.encoder.layer.7.attention.attention.dropout\n",
      "vit.encoder.layer.7.attention.output\n",
      "vit.encoder.layer.7.attention.output.dense\n",
      "vit.encoder.layer.7.attention.output.dropout\n",
      "vit.encoder.layer.7.intermediate\n",
      "vit.encoder.layer.7.intermediate.dense\n",
      "vit.encoder.layer.7.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.7.output\n",
      "vit.encoder.layer.7.output.dense\n",
      "vit.encoder.layer.7.output.dropout\n",
      "vit.encoder.layer.7.layernorm_before\n",
      "vit.encoder.layer.7.layernorm_after\n",
      "vit.encoder.layer.8\n",
      "vit.encoder.layer.8.attention\n",
      "vit.encoder.layer.8.attention.attention\n",
      "vit.encoder.layer.8.attention.attention.query\n",
      "vit.encoder.layer.8.attention.attention.key\n",
      "vit.encoder.layer.8.attention.attention.value\n",
      "vit.encoder.layer.8.attention.attention.dropout\n",
      "vit.encoder.layer.8.attention.output\n",
      "vit.encoder.layer.8.attention.output.dense\n",
      "vit.encoder.layer.8.attention.output.dropout\n",
      "vit.encoder.layer.8.intermediate\n",
      "vit.encoder.layer.8.intermediate.dense\n",
      "vit.encoder.layer.8.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.8.output\n",
      "vit.encoder.layer.8.output.dense\n",
      "vit.encoder.layer.8.output.dropout\n",
      "vit.encoder.layer.8.layernorm_before\n",
      "vit.encoder.layer.8.layernorm_after\n",
      "vit.encoder.layer.9\n",
      "vit.encoder.layer.9.attention\n",
      "vit.encoder.layer.9.attention.attention\n",
      "vit.encoder.layer.9.attention.attention.query\n",
      "vit.encoder.layer.9.attention.attention.key\n",
      "vit.encoder.layer.9.attention.attention.value\n",
      "vit.encoder.layer.9.attention.attention.dropout\n",
      "vit.encoder.layer.9.attention.output\n",
      "vit.encoder.layer.9.attention.output.dense\n",
      "vit.encoder.layer.9.attention.output.dropout\n",
      "vit.encoder.layer.9.intermediate\n",
      "vit.encoder.layer.9.intermediate.dense\n",
      "vit.encoder.layer.9.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.9.output\n",
      "vit.encoder.layer.9.output.dense\n",
      "vit.encoder.layer.9.output.dropout\n",
      "vit.encoder.layer.9.layernorm_before\n",
      "vit.encoder.layer.9.layernorm_after\n",
      "vit.encoder.layer.10\n",
      "vit.encoder.layer.10.attention\n",
      "vit.encoder.layer.10.attention.attention\n",
      "vit.encoder.layer.10.attention.attention.query\n",
      "vit.encoder.layer.10.attention.attention.key\n",
      "vit.encoder.layer.10.attention.attention.value\n",
      "vit.encoder.layer.10.attention.attention.dropout\n",
      "vit.encoder.layer.10.attention.output\n",
      "vit.encoder.layer.10.attention.output.dense\n",
      "vit.encoder.layer.10.attention.output.dropout\n",
      "vit.encoder.layer.10.intermediate\n",
      "vit.encoder.layer.10.intermediate.dense\n",
      "vit.encoder.layer.10.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.10.output\n",
      "vit.encoder.layer.10.output.dense\n",
      "vit.encoder.layer.10.output.dropout\n",
      "vit.encoder.layer.10.layernorm_before\n",
      "vit.encoder.layer.10.layernorm_after\n",
      "vit.encoder.layer.11\n",
      "vit.encoder.layer.11.attention\n",
      "vit.encoder.layer.11.attention.attention\n",
      "vit.encoder.layer.11.attention.attention.query\n",
      "vit.encoder.layer.11.attention.attention.key\n",
      "vit.encoder.layer.11.attention.attention.value\n",
      "vit.encoder.layer.11.attention.attention.dropout\n",
      "vit.encoder.layer.11.attention.output\n",
      "vit.encoder.layer.11.attention.output.dense\n",
      "vit.encoder.layer.11.attention.output.dropout\n",
      "vit.encoder.layer.11.intermediate\n",
      "vit.encoder.layer.11.intermediate.dense\n",
      "vit.encoder.layer.11.intermediate.intermediate_act_fn\n",
      "vit.encoder.layer.11.output\n",
      "vit.encoder.layer.11.output.dense\n",
      "vit.encoder.layer.11.output.dropout\n",
      "vit.encoder.layer.11.layernorm_before\n",
      "vit.encoder.layer.11.layernorm_after\n",
      "vit.layernorm\n",
      "classifier\n",
      "ViTForImageClassification(\n",
      "  (vit): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# backbone: viT\n",
    "model_checkpoint = \"google/vit-base-patch16-224-in21k\"  # pre-trained model from which to fine-tune\n",
    "# pretrained on ImageNet-21k\n",
    "\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    ignore_mismatched_sizes=True,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T00:57:12.715435Z",
     "start_time": "2024-04-27T00:57:10.131981Z"
    }
   },
   "id": "7b3c766b8b847b26"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 13682131 || trainable%: 0.00\n"
     ]
    }
   ],
   "source": [
    "# segformer 1.0: segformer\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-cityscapes-1024-1024\")\n",
    "\n",
    "num_classes = 20\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:26:00.438801Z",
     "start_time": "2024-04-30T17:25:59.716330Z"
    }
   },
   "id": "72481678c53ac8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5140 || all params: 13682388 || trainable%: 0.04\n"
     ]
    }
   ],
   "source": [
    "# segformer 1.1: segformer + linear probe(20 classes) \n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.decode_head.classifier = torch.nn.Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
    "print_trainable_parameters(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:26:10.467760Z",
     "start_time": "2024-04-30T17:26:09.595492Z"
    }
   },
   "id": "1d8ecd8dc1b6ff9f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 922644 || all params: 14599892 || trainable%: 6.32\n"
     ]
    }
   ],
   "source": [
    "# segformer 1.2: segformer + LoRA(attention,MLP, r = 64) + linear probe\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-cityscapes-1024-1024\")\n",
    "\n",
    "num_classes = 20\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"dense\",\"dense2\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"]\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.decode_head.classifier = torch.nn.Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:26:16.055608Z",
     "start_time": "2024-04-30T17:26:15.488876Z"
    }
   },
   "id": "57c64c19db35d71b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2097152 || all params: 15779283 || trainable%: 13.29\n"
     ]
    }
   ],
   "source": [
    "# segformer 1.3: segformer + LoRA(attention, r = 512) + linear probe\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-cityscapes-1024-1024\")\n",
    "\n",
    "num_classes = 20\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=512, \n",
    "    lora_alpha=16, \n",
    "    target_modules=[\"dense\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"]\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.decode_head.classifier = torch.nn.Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:26:20.111052Z",
     "start_time": "2024-04-30T17:26:19.821563Z"
    }
   },
   "id": "10c8c45acf5a55bb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5140 || all params: 13682388 || trainable%: 0.04\n"
     ]
    }
   ],
   "source": [
    "# segformer 2.0: segformer + linear probe\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.decode_head.classifier = torch.nn.Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:30:05.594213Z",
     "start_time": "2024-04-30T17:30:04.771031Z"
    }
   },
   "id": "b5534f39418c43ea"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 922644 || all params: 14599892 || trainable%: 6.32\n"
     ]
    }
   ],
   "source": [
    "# segformer 2.1: segformer + LoRA(attention,MLP, r = 64) + linear probe\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"dense\",\"dense2\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"]\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.decode_head.classifier = torch.nn.Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
    "print_trainable_parameters(model)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:31:00.806351Z",
     "start_time": "2024-04-30T17:30:59.962015Z"
    }
   },
   "id": "3766f8c4444b4697"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "nvidia/segformer-b6-finetuned-ade-512-512 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 304\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/models.py:1021\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1020\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1021\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/nvidia/segformer-b6-finetuned-ade-512-512/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRepositoryNotFoundError\u001B[0m                   Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 398\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1403\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001B[0m\n\u001B[1;32m   1401\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(head_call_error, RepositoryNotFoundError) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(head_call_error, GatedRepoError):\n\u001B[1;32m   1402\u001B[0m     \u001B[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001B[39;00m\n\u001B[0;32m-> 1403\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m head_call_error\n\u001B[1;32m   1404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1405\u001B[0m     \u001B[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1261\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001B[0m\n\u001B[1;32m   1260\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1261\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1262\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1268\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[1;32m   1271\u001B[0m     \u001B[38;5;66;03m# Cache the non-existence of the file and raise\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1674\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001B[0m\n\u001B[1;32m   1673\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[0;32m-> 1674\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1675\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHEAD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1676\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1679\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1680\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1681\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1682\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1683\u001B[0m hf_raise_for_status(r)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:369\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m follow_relative_redirects:\n\u001B[0;32m--> 369\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;66;03m# If redirection, we redirect only relative paths.\u001B[39;00m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;66;03m# This is useful in case of a renamed repository.\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:393\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    392\u001B[0m response \u001B[38;5;241m=\u001B[39m get_session()\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m--> 393\u001B[0m \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:352\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    344\u001B[0m     message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    345\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Client Error.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    346\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m make sure you are authenticated.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    351\u001B[0m     )\n\u001B[0;32m--> 352\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RepositoryNotFoundError(message, response) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m400\u001B[39m:\n",
      "\u001B[0;31mRepositoryNotFoundError\u001B[0m: 401 Client Error. (Request ID: Root=1-6631305f-35a7eead522acf07533d636a;7d15f0ca-df82-4451-9384-2f6c21f8b4a2)\n\nRepository Not Found for url: https://huggingface.co/nvidia/segformer-b6-finetuned-ade-512-512/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# segformer 2.2: segformer + LoRA(attention, r = 512) + linear probe\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSegformerForSemanticSegmentation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnvidia/segformer-b6-finetuned-ade-512-512\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m LoraConfig(\n\u001B[1;32m      5\u001B[0m     r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, \n\u001B[1;32m      6\u001B[0m     lora_alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     modules_to_save\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfc\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     12\u001B[0m model \u001B[38;5;241m=\u001B[39m get_peft_model(model, config)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:3015\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3012\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m commit_hash \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3013\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[1;32m   3014\u001B[0m         \u001B[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001B[39;00m\n\u001B[0;32m-> 3015\u001B[0m         resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3016\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3017\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3018\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3019\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3020\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3021\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3022\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3023\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3024\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3025\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3026\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_gated_repo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3027\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3028\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3029\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3030\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[1;32m   3031\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:421\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    417\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to access a gated repo.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mMake sure to have access to it at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    418\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    419\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 421\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    422\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    423\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to pass a token \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    424\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    425\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`token=<your_token>`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    426\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RevisionNotFoundError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    429\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    430\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor this model name. Check the model page at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    431\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available revisions.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    432\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: nvidia/segformer-b6-finetuned-ade-512-512 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# segformer 2.2: segformer + LoRA(attention, r = 512) + linear probe\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b4-finetuned-ade-512-512\")\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=512, \n",
    "    lora_alpha=16, \n",
    "    target_modules=[\"dense\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"fc\"]\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.decode_head.classifier = torch.nn.Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "print_trainable_parameters(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T17:54:40.106164Z",
     "start_time": "2024-04-30T17:54:39.830658Z"
    }
   },
   "id": "71014f0a9ee0f681"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74f77fa5ff5972f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
